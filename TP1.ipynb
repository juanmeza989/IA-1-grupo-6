{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jWUX78DM7n9T"
      },
      "source": [
        "# Temas Tratados en el Trabajo Práctico 1\n",
        "\n",
        "* Diferencia entre Inteligencia e Inteligencia Artificial.\n",
        "\n",
        "* Concepto de omnisciencia, aprendizaje y autonomía.\n",
        "\n",
        "* Definición de Agente y sus características. Clasificación de Agentes según su estructura.\n",
        "\n",
        "* Identificación y categorización del Entorno de Trabajo en tabla REAS.\n",
        "\n",
        "* Caracterización del Entorno de Trabajo.\n",
        "\n",
        "# Anotaciones\n",
        "\n",
        "\"Acordarse de la definición de agente\"\n",
        "\n",
        "En IA, un agente es cualquier entidad que percibe su entorno mediante sensores y actúa sobre él mediante actuadores, siguiendo algún criterio para maximizar su rendimiento. Puede ser físico (como un robot) o virtual (como un programa)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicios Teóricos\n",
        "\n",
        "#### 1. Defina con sus propias palabras inteligencia natural, inteligencia artificial y agente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Inteligencia Natural: Inteligencia de los seres vivos, los cuales tienen la capacidad de aprender de la experiencia a travez del razonamiento aunque este puede verse afectado por las emociones.\n",
        "\n",
        "* Inteligencia Artificial: Programa donde se busca que éste tome desiciones y/o aprenda de la experiencia a travez de una retroalimentación.\n",
        "\n",
        "* Agente: Aquel programa, mecanismo o ambos trabajando en conjunto en donde a travez de una retroalimentación ejecuta o no una acción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2. ¿Qué es un agente racional?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Idem anterior con la diferencia de que este busca maximizar el rendimiento."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3. ¿Un agente es siempre una computadora?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No, puede ser un simple mecanismo el cual ejecute una acción dependiendo del entorno, por ejemplo, un interruptor termomagnetico el cual debido a un estimulo  físico (sobrecarga) se ejecuta una acción."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4. Defina Omnisciencia, Aprendizaje y Autonomía."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Omnisciencia: es el conocimiento completo y absoluto de todas las cosas reales y posibles. Es la capacidad de saber todo lo que ha sucedido, lo que está sucediendo y lo que sucederá. \n",
        "\n",
        "* Aprendizaje: es el proceso mediante el cual se adquieren, modifican y desarrollan conocimientos, habilidades, conductas y valores a través de la experiencia, el estudio, la instrucción, el razonamiento y la observación. \n",
        "\n",
        "* Autonomía: es la capacidad de un individuo o entidad para tomar sus propias decisiones, regirse por sus propias normas y actuar de forma independiente, libre de presiones externas o internas. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5. Defina cada tipo de agente en función de su **estructura** y dé un ejemplo de cada categoría."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### **Tipos de Agentes**\n",
        "\n",
        "---\n",
        "\n",
        "* 1. Agentes Reactivos Simples\n",
        "Un agente reactivo simple toma decisiones basándose únicamente en la **percepción actual** del entorno. No tiene memoria ni considera el pasado. Su comportamiento se define por un conjunto de reglas `condición-acción`.\n",
        "* **Ejemplo**: Un **termostato** que se enciende si la temperatura es menor a 20°C y se apaga si es mayor. Solo reacciona a la temperatura del momento.\n",
        "\n",
        "---\n",
        "\n",
        "* 2. Agentes Reactivos Basados en Modelos\n",
        "Estos agentes tienen **memoria** de su estado interno y un \"modelo\" del mundo que les permite entender cómo sus acciones afectan el entorno. Toman decisiones basándose tanto en su percepción actual como en su historial.\n",
        "* **Ejemplo**: Un **conductor autónomo** que, para frenar, no solo detecta un obstáculo (percepción actual) sino que también considera su propia velocidad y posición (estado interno) para calcular la distancia de frenado necesaria. \n",
        "\n",
        "---\n",
        "\n",
        "* 3. Agentes Basados en Objetivos\n",
        "Además de tener un modelo del mundo, estos agentes poseen un **objetivo** que desean alcanzar. Toman decisiones eligiendo las acciones que los acercan a esa meta. Pueden razonar sobre las consecuencias futuras de sus acciones.\n",
        "* **Ejemplo**: Un **robot de logística** en un almacén. Su objetivo es mover un paquete de un punto A a un punto B. El agente no solo evita los obstáculos, sino que también calcula la ruta más eficiente para lograr su objetivo final.\n",
        "\n",
        "---\n",
        "\n",
        "* 4. Agentes Basados en Utilidad\n",
        "Estos agentes son una versión más avanzada de los agentes basados en objetivos. Toman decisiones que maximizan una función de **utilidad** o valor, lo que les permite elegir la mejor opción cuando hay múltiples caminos para lograr un objetivo o si existen diferentes metas.\n",
        "* **Ejemplo**: Un **asistente de viaje** que busca vuelos. Su objetivo es encontrar un vuelo, pero su función de utilidad considera factores como el precio, el tiempo de viaje y el número de escalas para encontrar la opción que más satisface al usuario.\n",
        "\n",
        "---\n",
        "\n",
        "* 5. Agentes que Aprenden\n",
        "Los agentes que aprenden son los más flexibles. Poseen un **elemento de aprendizaje** que les permite mejorar su rendimiento con el tiempo. Utilizan la experiencia y la retroalimentación para ajustar su comportamiento y funcionar en entornos desconocidos.\n",
        "* **Ejemplo**: Un **filtro de spam** en un correo electrónico. Inicialmente, puede tener reglas básicas, pero a medida que el usuario marca correos como spam, el agente aprende y ajusta sus criterios para mejorar su precisión.\n",
        "\n",
        "---\n",
        "\n",
        "##### **Propiedades del Entorno**\n",
        "\n",
        "* 1. Total o parcialmente observable\n",
        "\n",
        "Un entorno es totalmente observable si el agente puede percibir el estado completo del mundo a través de sus sensores en cada momento. Un agente en este tipo de entorno no necesita mantener un estado interno para saber lo que sucede.\n",
        "\n",
        "Un entorno es parcialmente observable si los sensores del agente no pueden acceder a toda la información relevante. La falta de visibilidad puede deberse a sensores defectuosos, ruido o a que simplemente el agente no puede ver ciertas partes del mundo.\n",
        "\n",
        "* 2. Determinista o estocástico\n",
        "\n",
        "Un entorno es determinista si el siguiente estado está completamente determinado por el estado actual y la acción del agente. No hay incertidumbre en los resultados.\n",
        "\n",
        "Un entorno es estocástico si la siguiente acción no se puede predecir con certeza, ya que puede haber factores aleatorios o impredecibles que influyan.\n",
        "\n",
        "* 3. Episódico o secuencial\n",
        "\n",
        "Un entorno es episódico si las decisiones del agente en cada \"episodio\" son independientes de las decisiones en episodios anteriores. Cada acción solo afecta a lo que sucede en el episodio actual.\n",
        "\n",
        "Un entorno es secuencial si las acciones del agente influyen en los estados futuros y, por tanto, en decisiones posteriores. Es decir, las decisiones tienen consecuencias a largo plazo.\n",
        "\n",
        "* 4. Estático o dinámico\n",
        "\n",
        "Un entorno es estático si no cambia mientras el agente está deliberando o pensando en una acción.\n",
        "\n",
        "Un entorno es dinámico si puede cambiar mientras el agente está en proceso de tomar una decisión.\n",
        "\n",
        "* 5. Discreto o contínuo\n",
        "\n",
        "Un entorno es discreto si el conjunto de percepciones y acciones es finito o \"enumerado\", es decir, se puede contar.\n",
        "\n",
        "Un entorno es continuo si las percepciones, las acciones o el tiempo son infinitos o tienen un rango de valores.\n",
        "\n",
        "* 6. Agente indivisual o multiagente\n",
        "\n",
        "Un entorno es de agente individual si solo hay un agente operando en él.\n",
        "\n",
        "Un entorno es multiagente si hay dos o más agentes. Estos pueden ser cooperativos (trabajando juntos para un objetivo común) o competitivos (con objetivos opuestos).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 6. Para los siguientes entornos de trabajo indique sus **propiedades**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "a. Una partida de ajedrez\n",
        "* **Totalmente observable:** Sí, el agente puede ver todas las piezas y sus posiciones en el tablero.\n",
        "* **Determinista:** Sí, los movimientos de las piezas tienen resultados predecibles y no hay azar.\n",
        "* **Secuencial:** Sí, cada movimiento afecta las futuras jugadas y el resultado final.\n",
        "* **Estático:** Sí, porque el entorno solo cambia cuando el agente realiza un movimiento.\n",
        "* **Discreto:** Sí, el número de movimientos, piezas y estados del tablero es finito.\n",
        "* **Multiagente:** Sí, hay dos agentes (los jugadores) compitiendo entre sí.\n",
        "\n",
        "\n",
        "b. Un partido de baloncesto\n",
        "* **Parcialmente observable:** Sí, un agente (jugador) no puede ver todas las posiciones y acciones de los demás jugadores en todo momento.\n",
        "* **Estocástico:** Sí, hay un grado de azar en los movimientos de la pelota, los rebotes y las acciones de los otros jugadores.\n",
        "* **Secuencial:** Sí, las decisiones de un jugador afectan el desarrollo del partido.\n",
        "* **Dinámico:** Sí, el entorno cambia constantemente debido a los movimientos de los jugadores y la pelota.\n",
        "* **Continuo:** Sí, las posiciones, velocidades y trayectorias de la pelota y los jugadores son continuas.\n",
        "* **Multiagente:** Sí, hay varios agentes (los jugadores de ambos equipos) interactuando.\n",
        "\n",
        "\n",
        "c. El juego Pacman\n",
        "* **Parcialmente observable:** Sí, Pacman no puede ver lo que hay en los pasillos que no están a su vista.\n",
        "* **Estocástico:** Sí, el movimiento de los fantasmas puede ser impredecible para el agente (Pacman).\n",
        "* **Secuencial:** Sí, las acciones pasadas (dónde ha comido los puntos) afectan las futuras decisiones y el resultado del juego.\n",
        "* **Dinámico:** Sí, el entorno cambia constantemente con el movimiento de Pacman y los fantasmas.\n",
        "* **Discreto:** Sí, los movimientos son en celdas de una cuadrícula y las acciones son limitadas.\n",
        "* **Multiagente:** Sí, Pacman interactúa con varios agentes (los fantasmas).\n",
        "\n",
        "\n",
        "d. El truco\n",
        "* **Parcialmente observable:** Sí, un jugador no conoce las cartas de los otros jugadores.\n",
        "* **Estocástico:** Sí, el reparto de cartas es aleatorio, lo que introduce un elemento de azar.\n",
        "* **Secuencial:** Sí, las decisiones de un jugador (cantar, envidar) tienen un impacto directo en las jugadas posteriores.\n",
        "* **Dinámico:** Sí, el entorno cambia continuamente con las acciones y el comportamiento de los otros jugadores.\n",
        "* **Discreto:** Sí, el número de cartas y de jugadas posibles es finito.\n",
        "* **Multiagente:** Sí, es un juego de múltiples agentes (los jugadores) que pueden formar equipos.\n",
        "\n",
        "\n",
        "e. Las damas\n",
        "* **Totalmente observable:** Sí, al igual que el ajedrez, todas las piezas son visibles en el tablero.\n",
        "* **Determinista:** Sí, cada movimiento tiene un resultado predecible.\n",
        "* **Secuencial:** Sí, los movimientos de un jugador afectan las futuras posibilidades del otro.\n",
        "* **Estático:** Sí, porque el tablero no cambia a menos que un jugador haga un movimiento.\n",
        "* **Discreto:** Sí, el número de movimientos y estados del tablero es finito.\n",
        "* **Multiagente:** Sí, hay dos agentes (los jugadores) que compiten.\n",
        "\n",
        "\n",
        "f. El juego tres en raya\n",
        "* **Totalmente observable:** Sí, el tablero es completamente visible para ambos jugadores.\n",
        "* **Determinista:** Sí, no hay azar en los movimientos.\n",
        "* **Secuencial:** Sí, cada jugada influye en las siguientes.\n",
        "* **Estático:** Sí, ya que el tablero no cambia entre turnos.\n",
        "* **Discreto:** Sí, el número de movimientos y estados del tablero es finito.\n",
        "* **Multiagente:** Sí, hay dos agentes (los jugadores) compitiendo.\n",
        "\n",
        "\n",
        "g. Un jugador de Pokémon Go\n",
        "* **Parcialmente observable:** Sí, el jugador solo puede ver los Pokémon cercanos y no lo que ocurre en todo el mapa.\n",
        "* **Estocástico:** Sí, la aparición de Pokémon es aleatoria.\n",
        "* **Secuencial:** Sí, las decisiones de un jugador (ir a una zona en particular) afectan las futuras recompensas (los Pokémon que podría capturar).\n",
        "* **Dinámico:** Sí, el entorno real cambia constantemente y los Pokémon aparecen y desaparecen.\n",
        "* **Continuo:** Sí, la ubicación del jugador y los Pokémon se mueve en un espacio geográfico continuo.\n",
        "* **Multiagente:** Sí, hay múltiples jugadores interactuando y compitiendo por los mismos recursos.\n",
        "\n",
        "\n",
        "h. Un robot explorador autónomo de Marte\n",
        "* **Parcialmente observable:** Sí, el robot no puede ver lo que hay detrás de un obstáculo o más allá de su línea de visión.\n",
        "* **Estocástico:** Sí, la topografía del terreno es incierta y pueden ocurrir eventos inesperados.\n",
        "* **Secuencial:** Sí, las decisiones de exploración afectan los futuros descubrimientos y la ruta a seguir.\n",
        "* **Dinámico:** Sí, el entorno podría cambiar debido a tormentas de polvo o pequeños movimientos de rocas.\n",
        "* **Continuo:** Sí, los movimientos del robot en el terreno y las mediciones de los sensores son continuos.\n",
        "* **Agente individual:** Sí, el robot opera por sí mismo para cumplir sus objetivos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 7. Elabore una tabla REAS para los siguientes entornos de trabajo:\n",
        "\n",
        "a. Crucigrama\n",
        "\n",
        "| Componente | Descripción |\n",
        "| :--- | :--- |\n",
        "| **Rendimiento** | Se mide por la velocidad con la que se completa el crucigrama y la cantidad de respuestas correctas. El objetivo es llenar la mayor cantidad de casillas con las palabras correctas en el menor tiempo posible. |\n",
        "| **Entorno** | Un tablero de crucigrama con palabras cruzadas y pistas. Es un entorno **estático**, **discreto** y **totalmente observable**. |\n",
        "| **Actuadores** | Las acciones del agente, como escribir una letra en una casilla específica o borrar una letra para corregir. |\n",
        "| **Sensores** | La capacidad de leer las pistas, identificar las casillas y percibir las letras que ya se han colocado en el tablero. |\n",
        "\n",
        "\n",
        "b. Taxi circulando\n",
        "\n",
        "| Componente | Descripción |\n",
        "| :--- | :--- |\n",
        "| **Rendimiento** | Se evalúa por la seguridad (evitar accidentes), la eficiencia (llegar al destino en el menor tiempo posible) y la satisfacción del cliente (ofrecer una experiencia de viaje cómoda). |\n",
        "| **Entorno** | Las carreteras, otros vehículos, peatones, señales de tráfico, semáforos, el clima y los pasajeros. Es un entorno **dinámico**, **estocástico** y **parcialmente observable**. |\n",
        "| **Actuadores** | El volante (girar), los pedales (acelerar y frenar), la transmisión (cambiar de marcha) y los indicadores de dirección (señalizar). |\n",
        "| **Sensores** | Cámaras (visión de la carretera), radar (distancia a otros vehículos), GPS (posición), micrófono (interacción con el pasajero) y el motor de temperatura (estado del coche). |\n",
        "\n",
        "\n",
        "c. Robot clasificador de piezas\n",
        "\n",
        "| Componente | Descripción |\n",
        "| :--- | :--- |\n",
        "| **Rendimiento** | Se mide por la precisión (clasificar correctamente las piezas), la velocidad (cantidad de piezas clasificadas por minuto) y la eficiencia energética. |\n",
        "| **Entorno** | Una cinta transportadora con piezas de diferentes formas, tamaños y colores, y los contenedores de clasificación. Es un entorno **episódico** y **estático** (la cinta se mueve, pero el robot no). |\n",
        "| **Actuadores** | Un brazo robótico para recoger las piezas y la capacidad de soltar las piezas en el contenedor correcto. |\n",
        "| **Sensores** | Sensores de visión (cámaras) para identificar la forma, tamaño y color de las piezas, y sensores táctiles para determinar la posición y el agarre de la pieza. |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicios Prácticos\n",
        "\n",
        "8. La Hormiga de Langton es un agente capaz de modificar el estado de la casilla en la que se encuentra para colorearla o bien de blanco o de negro. Al comenzar, la ubicación de la hormiga es una casilla aleatoria y mira hacia una de las cuatro casillas adyacentes. Si...\n",
        "\n",
        "* ... la casilla sobre la que está es blanca, cambia el color del cuadrado, gira noventa grados a la derecha y avanza un cuadrado.\n",
        "\n",
        "* ... la casilla sobre la que está es negra, cambia el color del cuadrado, gira noventa grados a la izquierda y avanza un cuadrado.\n",
        "\n",
        "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "\n",
        "| Elemento | Descripción |\n",
        "| :--- | :--- |\n",
        "| **R** (Representación) | La hormiga conoce su orientación (Norte, Sur, Este, Oeste) y el estado de la celda actual (blanca o negra). El plano se representa como una matriz o diccionario donde cada coordenada tiene un color (0 = blanco, 1 = negro). |\n",
        "| **E** (Entorno) | Infinito (o lo suficientemente grande para la simulación), discreto, determinista, **parcialmente observable** (la hormiga solo percibe la celda actual), estático (no cambia por sí mismo, solo por acción del agente). |\n",
        "| **A** (Actuadores) | Cambiar el color de la celda, girar 90° (a la izquierda o a la derecha) y avanzar una celda en la dirección actual. |\n",
        "| **S** (Sensores) | Detectar el color de la celda actual (blanco o negro). |\n",
        "\n",
        "\n",
        "* **Accesibilidad:** **Parcialmente accesible**, ya que el agente solo puede percibir el estado de la celda en la que se encuentra en ese momento.\n",
        "* **Determinista:** **Sí**, las acciones de la hormiga siempre producen el mismo resultado predecible.\n",
        "* **Episódico:** **No**, el estado actual del entorno y el comportamiento del agente dependen directamente del historial de acciones y cambios previos.\n",
        "* **Estático/Dinámico:** **Estático**, el entorno no cambia por sí solo, solo lo hace como resultado de las acciones de la hormiga.\n",
        "* **Discreto/Continuo:** **Discreto**, ya que el entorno está formado por una rejilla finita de celdas individuales.\n",
        "* **Número de agentes:** **Un solo agente** (la hormiga).\n",
        "\n",
        "    ¿Observa que se repite algún patrón? De ser así, ¿a partir de qué iteración?\n",
        "\n",
        "Se observa un patron que para la iteracion número 12000 termina la repetición del patrón.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import deque\n",
        "\n",
        "# Definición de movimientos: N, E, S, O\n",
        "movs = [(0, 1), (1, 0), (0, -1), (-1, 0)]\n",
        "\n",
        "# Estado inicial\n",
        "x, y = 0, 0\n",
        "direccion = 0  # 0=N, 1=E, 2=S, 3=O\n",
        "celdas = {}    # Diccionario: (x, y) -> 0 (blanco) o 1 (negro)\n",
        "\n",
        "# Parámetros de simulación\n",
        "iteraciones = 20000\n",
        "limite = 50\n",
        "velocidad = 0.00001\n",
        "\n",
        "# Para detección de patrón\n",
        "historial = deque(maxlen=208)  # 2 ciclos de 104 pasos\n",
        "inicio_patron = None\n",
        "\n",
        "# Configuración gráfica\n",
        "plt.ion()\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "ax.set_aspect(\"equal\")\n",
        "ax.set_xlim(-limite, limite)\n",
        "ax.set_ylim(-limite, limite)\n",
        "ax.set_title(\"Hormiga de Langton\")\n",
        "\n",
        "# Lista de puntos negros\n",
        "negros_x = []\n",
        "negros_y = []\n",
        "\n",
        "# Dibujar los puntos negros iniciales\n",
        "puntos_negros = ax.scatter(negros_x, negros_y, c=\"black\", s=10)\n",
        "hormiga_plot, = ax.plot([x], [y], \"ro\")  # listas, no enteros\n",
        "\n",
        "for paso in range(iteraciones):\n",
        "    if not plt.fignum_exists(fig.number):  # si cerraste la ventana\n",
        "        break\n",
        "\n",
        "    # Guardar estado para detección de patrón\n",
        "    color = celdas.get((x, y), 0)\n",
        "    historial.append((x, y, direccion, color))\n",
        "\n",
        "    if len(historial) == historial.maxlen:\n",
        "        mitad = len(historial) // 2\n",
        "        if list(historial)[:mitad] == list(historial)[mitad:]:\n",
        "            inicio_patron = paso - mitad\n",
        "            print(f\"Patrón repetitivo detectado a partir de la iteración {inicio_patron}\")\n",
        "            break\n",
        "\n",
        "    # Reglas de la hormiga\n",
        "    if color == 0:  # blanco → gira derecha, pinta negro\n",
        "        direccion = (direccion + 1) % 4\n",
        "        celdas[(x, y)] = 1\n",
        "        negros_x.append(x)\n",
        "        negros_y.append(y)\n",
        "    else:  # negro → gira izquierda, pinta blanco\n",
        "        direccion = (direccion - 1) % 4\n",
        "        celdas[(x, y)] = 0\n",
        "        if (x, y) in zip(negros_x, negros_y):\n",
        "            idx = list(zip(negros_x, negros_y)).index((x, y))\n",
        "            negros_x.pop(idx)\n",
        "            negros_y.pop(idx)\n",
        "\n",
        "    # Avanzar\n",
        "    dx, dy = movs[direccion]\n",
        "    x += dx\n",
        "    y += dy\n",
        "\n",
        "    # Actualizar puntos negros y hormiga\n",
        "    puntos_negros.set_offsets(list(zip(negros_x, negros_y)))\n",
        "    hormiga_plot.set_data([x], [y])\n",
        "\n",
        "    plt.pause(velocidad)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()\n",
        "\n",
        "if inicio_patron:\n",
        "    print(f\"La hormiga entró en el patrón a partir de la iteración {inicio_patron}\")\n",
        "else:\n",
        "    print(\"No se detectó patrón repetitivo en el rango simulado.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "9. El Juego de la Vida de Conway consiste en un tablero donde cada casilla representa una célula, de manera que a cada célula le rodean 8 vecinas. Las células tienen dos estados: están *vivas* o *muertas*. En cada iteración, el estado de todas las células se tiene en cuenta para calcular el estado siguiente en simultáneo de acuerdo a las siguientes acciones:\n",
        "\n",
        "* Nacer: Si una célula muerta tiene exactamente 3 células vecinas vivas, dicha célula pasa a estar viva.\n",
        "\n",
        "* Morir: Una célula viva puede morir sobrepoblación cuando tiene más de tres vecinos alrededor o por aislamiento si tiene solo un vecino o ninguno.\n",
        "\n",
        "* Vivir: una célula se mantiene viva si tiene 2 o 3 vecinos a su alrededor.\n",
        "\n",
        "    Caracterice el agente con su tabla REAS y las propiedades del entorno para después programarlo en Python:\n",
        "\n",
        "    ¡Claro! Aquí tienes la información sobre el juego de la vida de Conway, formateada en Markdown, tal como lo pediste.\n",
        "\n",
        "---\n",
        "\n",
        "Tabla REAS (Representación, Entorno, Actuadores y Sensores)\n",
        "\n",
        "| Elemento | Descripción |\n",
        "| :--- | :--- |\n",
        "| **R** (Representación) | El sistema mantiene una **matriz (o lista de listas)** que representa el tablero, donde cada celda puede estar en un estado: **0 (muerta)** o **1 (viva)**. |\n",
        "| **E** (Entorno) | Un tablero **bidimensional finito** (o toroidal si los bordes están conectados). Es **discreto** en espacio y tiempo, **determinista**, y **estático** entre cada actualización. |\n",
        "| **A** (Actuadores) | **Actualizar el estado de todas las celdas** simultáneamente basándose en las reglas del juego: nacer, morir o vivir. |\n",
        "| **S** (Sensores) | **Contar el número de células vivas vecinas** (las 8 celdas que rodean a la celda actual). |\n",
        "\n",
        "---\n",
        "\n",
        "Propiedades del Entorno\n",
        "\n",
        "* **Accesibilidad:** **Totalmente accesible**, ya que el sistema tiene acceso completo al estado de todas las celdas del tablero.\n",
        "* **Determinista:** **Sí**, las reglas del juego son fijas y siempre producen el mismo resultado para un estado inicial dado.\n",
        "* **Episódico:** **No**, el estado del tablero en un momento dado es completamente dependiente del estado en la iteración anterior.\n",
        "* **Estático/Dinámico:** El entorno es **estático** entre cada paso de simulación, pero el estado general del sistema es dinámico, ya que cambia con cada actualización.\n",
        "* **Discreto/Continuo:** **Discreto**, tanto en el espacio (una cuadrícula de celdas) como en el tiempo (iteraciones o \"generaciones\").\n",
        "* **Número de agentes:** Puede interpretarse como un sistema **sin un agente único**. En cambio, funciona como un autómata celular, donde **cada celda actúa como un agente local** que sigue las mismas reglas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parámetros\n",
        "filas, columnas = 50, 50\n",
        "iteraciones = 200\n",
        "velocidad = 0.1  # segundos entre pasos\n",
        "\n",
        "# Estado inicial aleatorio\n",
        "tablero = np.random.choice([0, 1], size=(filas, columnas))\n",
        "\n",
        "# Configuración de gráfico (se crea solo una vez)\n",
        "plt.ion()\n",
        "fig, ax = plt.subplots()\n",
        "img = ax.imshow(tablero, cmap=\"binary\", interpolation=\"nearest\")\n",
        "ax.set_title(\"Juego de la Vida de Conway\")\n",
        "\n",
        "# Función para contar vecinos vivos\n",
        "def contar_vecinos(tablero, x, y):\n",
        "    vecinos = [\n",
        "        tablero[(x-1) % filas, (y-1) % columnas],\n",
        "        tablero[(x-1) % filas, y],\n",
        "        tablero[(x-1) % filas, (y+1) % columnas],\n",
        "        tablero[x, (y-1) % columnas],\n",
        "        tablero[x, (y+1) % columnas],\n",
        "        tablero[(x+1) % filas, (y-1) % columnas],\n",
        "        tablero[(x+1) % filas, y],\n",
        "        tablero[(x+1) % filas, (y+1) % columnas],\n",
        "    ]\n",
        "    return sum(vecinos)\n",
        "\n",
        "# Simulación\n",
        "for _ in range(iteraciones):\n",
        "    if not plt.fignum_exists(fig.number):  # si cerraste la ventana, cortar bucle\n",
        "        break\n",
        "\n",
        "    nuevo_tablero = np.zeros((filas, columnas), dtype=int)\n",
        "    for i in range(filas):\n",
        "        for j in range(columnas):\n",
        "            vivos = contar_vecinos(tablero, i, j)\n",
        "            if tablero[i, j] == 1 and vivos in [2, 3]:\n",
        "                nuevo_tablero[i, j] = 1\n",
        "            elif tablero[i, j] == 0 and vivos == 3:\n",
        "                nuevo_tablero[i, j] = 1\n",
        "    tablero = nuevo_tablero\n",
        "\n",
        "    img.set_data(tablero)  # actualiza imagen sin redibujar ventana\n",
        "    plt.pause(velocidad)\n",
        "\n",
        "plt.ioff()\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "oXcAF__NmgG5"
      },
      "source": [
        "# Bibliografía\n",
        "\n",
        "[Russell, S. & Norvig, P. (2004) _Inteligencia Artificial: Un Enfoque Moderno_. Pearson Educación S.A. (2a Ed.) Madrid, España](https://www.academia.edu/8241613/Inteligencia_Aritificial_Un_Enfoque_Moderno_2da_Edici%C3%B3n_Stuart_J_Russell_y_Peter_Norvig)\n",
        "\n",
        "[Poole, D. & Mackworth, A. (2023) _Artificial Intelligence: Foundations of Computational Agents_. Cambridge University Press (3a Ed.) Vancouver, Canada](https://artint.info/3e/html/ArtInt3e.html)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
